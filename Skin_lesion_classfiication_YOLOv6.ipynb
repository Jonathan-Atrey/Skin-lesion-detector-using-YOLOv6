{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbXOUztkULxk",
        "outputId": "7f7939bd-3651-4ff5-dd94-ff267028e216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XmMhDuCiWgxJ",
        "outputId": "06754183-6c1e-45eb-9b10-ff5f480b0f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd gdrive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crs3Nh55Wq2B",
        "outputId": "6e147fde-a534-481a-f350-0fe20424afd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd yolov6env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKT9x3tMXBsV",
        "outputId": "161dc756-9b59-49ed-a747-9fd4e429a640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/yolov6env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/meituan/YOLOv6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NnhSIqsXDmV",
        "outputId": "812533bb-b9a8-4384-a991-af88a4234a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'YOLOv6' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd YOLOv6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOt6_GENXKG1",
        "outputId": "3c2983b2-b6fd-4ed2-e019-61d739b89a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/yolov6env/YOLOv6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCMv7TnHXM5Z",
        "outputId": "66d40458-f92a-4c8b-92b4-8390b91baac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.13.0+cu113)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 35.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.7.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (4.64.0)\n",
            "Collecting addict>=2.4.0\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: tensorboard>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.8.0)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.0.4)\n",
            "Collecting onnx>=1.10.0\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 55.8 MB/s \n",
            "\u001b[?25hCollecting onnx-simplifier>=0.3.6\n",
            "  Downloading onnx_simplifier-0.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 60.1 MB/s \n",
            "\u001b[?25hCollecting thop\n",
            "  Downloading thop-0.1.1.post2207130030-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.47.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 13)) (3.2.2)\n",
            "Collecting rich\n",
            "  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 74.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.2.0)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (2.6.1)\n",
            "Installing collected packages: commonmark, rich, onnx, thop, PyYAML, onnx-simplifier, addict\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 addict-2.4.0 commonmark-0.9.1 onnx-1.12.0 onnx-simplifier-0.4.2 rich-12.5.1 thop-0.1.1.post2207130030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVUNSstbXYk8",
        "outputId": "258f7395-16ce-4124-ba44-49f761ebd18c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1 MB 1.3 MB/s eta 0:14:43tcmalloc: large alloc 1147494400 bytes == 0x3a5c6000 @  0x7f9b73345615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████               | 1055.7 MB 1.3 MB/s eta 0:12:00tcmalloc: large alloc 1434370048 bytes == 0x7ec1c000 @  0x7f9b73345615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████▋          | 1336.2 MB 1.3 MB/s eta 0:08:36tcmalloc: large alloc 1792966656 bytes == 0x3a4e000 @  0x7f9b73345615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.2 MB/s eta 0:03:59tcmalloc: large alloc 2241208320 bytes == 0x6e836000 @  0x7f9b73345615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0xf4198000 @  0x7f9b733441e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2477727744 bytes == 0x16a3f2000 @  0x7f9b73345615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 2.9 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6 MB 206 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.1\n",
            "  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 31.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (4.1.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.0+cu113\n",
            "    Uninstalling torchvision-0.13.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.0+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.0+cu113\n",
            "    Uninstalling torchaudio-0.12.0+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.8.1+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available() \n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "erXIUN8KXPHf",
        "outputId": "3f8d69dc-4002-40ad-ab34-8fc8f54d24fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py --batch 32 --conf configs/yolov6s_finetune.py --data-path dataset.yaml --device 0 --epochs 20 --eval-interval 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e15BgQ_f0Z9",
        "outputId": "0bc06eba-a83e-41b0-a449-39dcf634ad6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 1 GPU for training... \n",
            "training args are: Namespace(batch_size=32, check_images=False, check_labels=False, conf_file='configs/yolov6s_finetune.py', data_path='dataset.yaml', device='0', dist_url='env://', epochs=20, eval_final_only=False, eval_interval=2, gpu_count=0, heavy_eval_range=50, img_size=640, local_rank=-1, name='exp', output_dir='./runs/train', rank=-1, resume=False, save_dir='runs/train/exp9', workers=8, world_size=1)\n",
            "\n",
            "Train: Final numbers of valid images: 268/ labels: 268. \n",
            "0.0s for dataset initialization.\n",
            "Convert to COCO format\n",
            "100% 15/15 [00:00<00:00, 63230.71it/s]\n",
            "Convert to COCO format finished. Resutls saved in /content/gdrive/MyDrive/yolov6env/YOLOv6/dataset/annotations/instances_val.json\n",
            "Val: Final numbers of valid images: 15/ labels: 15. \n",
            "0.1s for dataset initialization.\n",
            "Loading state_dict from /content/gdrive/MyDrive/yolov6env/YOLOv6/yolov6t.pt for fine-tuning...\n",
            "Model: Model(\n",
            "  (backbone): EfficientRep(\n",
            "    (stem): RepVGGBlock(\n",
            "      (nonlinearity): ReLU(inplace=True)\n",
            "      (se): Identity()\n",
            "      (rbr_dense): Sequential(\n",
            "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (rbr_1x1): Sequential(\n",
            "        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_2): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_3): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_4): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (3): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (4): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_5): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): SimSPPF(\n",
            "        (cv1): SimConv(\n",
            "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): SimConv(\n",
            "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (neck): RepPANNeck(\n",
            "    (Rep_p4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_p3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_n3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_n4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer0): SimConv(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample0): Transpose(\n",
            "      (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (reduce_layer1): SimConv(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample1): Transpose(\n",
            "      (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (downsample2): SimConv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (downsample1): SimConv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (detect): Detect(\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (obj_preds): ModuleList(\n",
            "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (stems): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Training start...\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "      0/19     2.675     1.804     6.262      3.39: 100% 9/9 [00:11<00:00,  1.23s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  2.24it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.038\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.150\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.121\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
            "Epoch: 0 | mAP@0.5: 0.14999131492096576 | mAP@0.50:0.95: 0.03786308455406944\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "      1/19     2.501     1.687     5.966     3.329: 100% 9/9 [00:13<00:00,  1.49s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  2.11it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.11s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.073\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.115\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.343\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.376\n",
            "Epoch: 1 | mAP@0.5: 0.24326580527726957 | mAP@0.50:0.95: 0.09361416404798374\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "      2/19     2.494     1.704     5.529     3.078: 100% 9/9 [00:13<00:00,  1.49s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.32it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.110\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.234\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.316\n",
            "Epoch: 2 | mAP@0.5: 0.15122059825030124 | mAP@0.50:0.95: 0.07188970921779171\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "      3/19     2.573     1.696     5.323     2.814: 100% 9/9 [00:12<00:00,  1.42s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.36it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.29s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.208\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.316\n",
            "Epoch: 3 | mAP@0.5: 0.1366538751777276 | mAP@0.50:0.95: 0.05703740415267906\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "      4/19     2.365     1.609     4.879      2.62: 100% 9/9 [00:13<00:00,  1.48s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.70it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.124\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.027\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.142\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
            "Epoch: 4 | mAP@0.5: 0.1242821289069335 | mAP@0.50:0.95: 0.05366803688268359\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "      5/19     2.276     1.541     4.538      2.48: 100% 9/9 [00:14<00:00,  1.56s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.075\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.220\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.089\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.229\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.900\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\n",
            "Epoch: 5 | mAP@0.5: 0.22044428045289 | mAP@0.50:0.95: 0.0748255634087718\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "      6/19     2.349     1.572      4.56     2.277: 100% 9/9 [00:13<00:00,  1.54s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.19it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.021\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.376\n",
            "Epoch: 6 | mAP@0.5: 0.2620172884663088 | mAP@0.50:0.95: 0.09662744023910402\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "      7/19     2.243     1.554     4.306     2.126: 100% 9/9 [00:13<00:00,  1.46s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.48it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.45s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.10s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.166\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.433\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.252\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389\n",
            "Epoch: 7 | mAP@0.5: 0.4332364393511406 | mAP@0.50:0.95: 0.16597450923892051\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "      8/19      2.29     1.562     4.283     2.113: 100% 9/9 [00:12<00:00,  1.38s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.56it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.385\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.147\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.189\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n",
            "Epoch: 8 | mAP@0.5: 0.3850471125846792 | mAP@0.50:0.95: 0.18598608363394709\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "      9/19     2.263     1.524     4.003     1.957: 100% 9/9 [00:14<00:00,  1.61s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.18it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.139\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.322\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.271\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.386\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
            "Epoch: 9 | mAP@0.5: 0.3218486928057885 | mAP@0.50:0.95: 0.13940600352535992\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "     10/19     2.267     1.488     4.083       1.9: 100% 9/9 [00:13<00:00,  1.50s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.406\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.398\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n",
            "Epoch: 10 | mAP@0.5: 0.40560107653803434 | mAP@0.50:0.95: 0.20204034006181992\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "     11/19     2.222     1.514     4.079     1.844: 100% 9/9 [00:12<00:00,  1.44s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.46it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.10s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.330\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.076\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.151\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\n",
            "Epoch: 11 | mAP@0.5: 0.33003425342534254 | mAP@0.50:0.95: 0.16233380973934555\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "     12/19     2.251     1.484     4.011     1.709: 100% 9/9 [00:13<00:00,  1.47s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.31it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.10s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.426\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.451\n",
            "Epoch: 12 | mAP@0.5: 0.17717822690040774 | mAP@0.50:0.95: 0.0930171276409629\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "     13/19      2.29     1.435     3.905     1.742: 100% 9/9 [00:13<00:00,  1.50s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.34it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.144\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.267\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.420\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.462\n",
            "Epoch: 13 | mAP@0.5: 0.2670724864694261 | mAP@0.50:0.95: 0.14398520426171457\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "     14/19     2.328     1.477     3.911     1.715: 100% 9/9 [00:13<00:00,  1.50s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.63it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.35s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.180\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.439\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.437\n",
            "Epoch: 14 | mAP@0.5: 0.312156595065 | mAP@0.50:0.95: 0.17997802209142205\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "     15/19     2.359     1.476     3.937     1.706: 100% 9/9 [00:14<00:00,  1.56s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.319\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.438\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.460\n",
            "Epoch: 15 | mAP@0.5: 0.31936202508421496 | mAP@0.50:0.95: 0.17388753012228012\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "     16/19     2.202     1.503     3.881     1.632: 100% 9/9 [00:14<00:00,  1.59s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.50it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.361\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508\n",
            "Epoch: 16 | mAP@0.5: 0.36055871374823173 | mAP@0.50:0.95: 0.1879670321339874\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "     17/19     2.255      1.42      3.82     1.634: 100% 9/9 [00:13<00:00,  1.47s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.72it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n",
            "Epoch: 17 | mAP@0.5: 0.3415669314184166 | mAP@0.50:0.95: 0.19939368387388184\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "     18/19     2.174     1.401       3.7     1.612: 100% 9/9 [00:12<00:00,  1.44s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.25it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.161\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n",
            "Epoch: 18 | mAP@0.5: 0.33851801258931996 | mAP@0.50:0.95: 0.17474160916104237\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "     19/19     2.098     1.334     3.525       1.6: 100% 9/9 [00:12<00:00,  1.37s/it]\n",
            "Inferencing model in val datasets.: 100% 1/1 [00:00<00:00,  1.43it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp9/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.181\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.165\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n",
            "Epoch: 19 | mAP@0.5: 0.3284300176692047 | mAP@0.50:0.95: 0.18071619595671146\n",
            "\n",
            "Training completed in 0.092 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/infer.py --weights runs/train/exp9/weights/best_ckpt.pt --source /content/gdrive/MyDrive/yolov6env/YOLOv6/dataset/images/test/test1.jpg --yaml dataset.yaml --device 0 "
      ],
      "metadata": {
        "id": "9TnkZkXuBXdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "925b5343-d7be-44ee-f618-be53fd4336a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(agnostic_nms=False, classes=None, conf_thres=0.25, device='0', half=False, hide_conf=False, hide_labels=False, img_size=640, iou_thres=0.45, max_det=1000, name='exp', project='runs/inference', save_img=True, save_txt=False, source='/content/gdrive/MyDrive/yolov6env/YOLOv6/dataset/images/test/test1.jpg', weights='runs/train/exp9/weights/best_ckpt.pt', yaml='dataset.yaml')\n",
            "Save directory already existed\n",
            "Loading checkpoint from runs/train/exp9/weights/best_ckpt.pt\n",
            "\n",
            "Fusing model...\n",
            "Switch model to deploy modality.\n",
            "100% 1/1 [00:00<00:00,  2.46it/s]\n",
            "Results saved to runs/inference/exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/infer.py --weights runs/train/exp9/weights/best_ckpt.pt --source /content/gdrive/MyDrive/yolov6env/YOLOv6/dataset/images/test/test2.jpg --yaml dataset.yaml --device 0 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUFTAbXVvjYt",
        "outputId": "5aeb20e7-e783-40d6-e312-80af94e05fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(agnostic_nms=False, classes=None, conf_thres=0.25, device='0', half=False, hide_conf=False, hide_labels=False, img_size=640, iou_thres=0.45, max_det=1000, name='exp', project='runs/inference', save_img=True, save_txt=False, source='/content/gdrive/MyDrive/yolov6env/YOLOv6/dataset/images/test/test2.jpg', weights='runs/train/exp9/weights/best_ckpt.pt', yaml='dataset.yaml')\n",
            "Save directory already existed\n",
            "Loading checkpoint from runs/train/exp9/weights/best_ckpt.pt\n",
            "\n",
            "Fusing model...\n",
            "Switch model to deploy modality.\n",
            "100% 1/1 [00:00<00:00,  5.26it/s]\n",
            "Results saved to runs/inference/exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/infer.py --weights runs/train/exp9/weights/best_ckpt.pt --source /content/gdrive/MyDrive/yolov6env/YOLOv6/dataset/images/test/test3.jpg --yaml dataset.yaml --device 0 "
      ],
      "metadata": {
        "id": "VrYutAIKwWJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7abc26d-629e-49d8-f3b1-c83893663557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(agnostic_nms=False, classes=None, conf_thres=0.25, device='0', half=False, hide_conf=False, hide_labels=False, img_size=640, iou_thres=0.45, max_det=1000, name='exp', project='runs/inference', save_img=True, save_txt=False, source='/content/gdrive/MyDrive/yolov6env/YOLOv6/dataset/images/test/test3.jpg', weights='runs/train/exp9/weights/best_ckpt.pt', yaml='dataset.yaml')\n",
            "Save directory already existed\n",
            "Loading checkpoint from runs/train/exp9/weights/best_ckpt.pt\n",
            "\n",
            "Fusing model...\n",
            "Switch model to deploy modality.\n",
            "100% 1/1 [00:00<00:00,  3.10it/s]\n",
            "Results saved to runs/inference/exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7epL-cvoy6s2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}